{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "from IPython.display import display\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#general tooling\n",
    "from functools import partial\n",
    "\n",
    "#custom functions\n",
    "import sys\n",
    "sys.path.append('../data/')\n",
    "sys.path.append('../src/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston,\\\n",
    "                            load_diabetes,\\\n",
    "                            load_iris,\\\n",
    "                            fetch_california_housing,\\\n",
    "                            fetch_species_distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "species = fetch_species_distributions(data_home='../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "\n",
    "X = pd.DataFrame(iris.data,columns=['sepal_length','sepal_width','petal_length','petal_width'])\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   sepal_length  sepal_width  petal_length  petal_width\n",
       " 0           5.1          3.5           1.4          0.2\n",
       " 1           4.9          3.0           1.4          0.2\n",
       " 2           4.7          3.2           1.3          0.2\n",
       " 3           4.6          3.1           1.5          0.2\n",
       " 4           5.0          3.6           1.4          0.2,\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(),y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. create missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_numericals = ['sepal_length','sepal_width','petal_length','petal_width']\n",
    "features_mean_imputation = ['sepal_length']\n",
    "features_median_imputation = ['sepal_width']\n",
    "features_no_imputation = ['petal_length','petal_width']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('features', CustomFeatureSelector(columns=[['sepal_length'], ['sepal_width'], ['petal_length', 'petal_width']])), ('classifier', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, m...\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pipeline\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "#Transformers\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder,Imputer,StandardScaler\n",
    "from transformers import ColumnSelector,CustomFeatureSelector\n",
    "#Estimators\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "# specification of different model types and their defaults\n",
    "model_dictionary = {'xgb': XGBClassifier(),\n",
    "                   'lgbm': LGBMClassifier()}\n",
    "\n",
    "model_name = 'xgb'\n",
    "\n",
    "estimator = Pipeline([\n",
    "        ('features',CustomFeatureSelector(columns=[features_mean_imputation,features_median_imputation,features_no_imputation]) \n",
    "#          FeatureUnion(\n",
    "#             [                \n",
    "#                 ('mean_imputations', Pipeline([\n",
    "#                                 ('selector', ColumnSelector(columns=features_mean_imputation))\n",
    "#                                ,('imputer', Imputer(strategy='mean'))                            ])),\n",
    "#                 ('median_imputations', Pipeline([\n",
    "#                                 ('selector', ColumnSelector(columns=features_median_imputation))\n",
    "#                                ,('imputer', Imputer(strategy='median'))                            ])),\n",
    "#                 ('no_imputations', Pipeline([\n",
    "#                                 ('selector', ColumnSelector(columns=features_no_imputation))        ]))\n",
    "#             ], \n",
    "#         )\n",
    "            ),  \n",
    "        ('classifier', model_dictionary[model_name]),\n",
    "])\n",
    "\n",
    "estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0. Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, make_scorer,accuracy_score\n",
    "\n",
    "def MSE(y_true,y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    #print('MSE: %2.3f' % mse)\n",
    "    return mse\n",
    "\n",
    "def R2(y_true,y_pred):    \n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    #print('R2: %2.3f' % r2)\n",
    "    return r2\n",
    "\n",
    "def current_scorer():\n",
    "    return make_scorer(accuracy_score, greater_is_better=True) # change for false if using MSE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. TPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hyperopt import hp, tpe,Trials,STATUS_OK\n",
    "from hyperopt.fmin import fmin\n",
    "\n",
    "from sklearn.model_selection import cross_val_score,RepeatedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- iter 0: mean_score 0.94533\n",
      "- iter 1: mean_score 0.94533\n",
      "- iter 2: mean_score 0.94133\n",
      "- iter 3: mean_score 0.93867\n",
      "- iter 4: mean_score 0.93867\n",
      "- iter 5: mean_score 0.94000\n",
      "- iter 6: mean_score 0.93200\n",
      "- iter 7: mean_score 0.93867\n",
      "- iter 8: mean_score 0.94000\n",
      "- iter 9: mean_score 0.94133\n",
      "- iter 10: mean_score 0.95867\n",
      "- iter 11: mean_score 0.94400\n",
      "- iter 12: mean_score 0.94267\n",
      "- iter 13: mean_score 0.93733\n",
      "- iter 14: mean_score 0.93867\n",
      "- iter 15: mean_score 0.94533\n",
      "- iter 16: mean_score 0.94400\n",
      "- iter 17: mean_score 0.94000\n",
      "- iter 18: mean_score 0.94000\n",
      "- iter 19: mean_score 0.95067\n",
      "best result with accuracy score 0.9586666666666668\n",
      "{'features__columns': 1, 'classifier__min_child_weight': 1.0, 'classifier__learning_rate': 0.225, 'classifier__n_estimators': 275.0, '0': 0, 'classifier__reg_lambda': 1.0, 'classifier__reg_alpha': 1.0, 'classifier__gamma': 0.9, 'classifier__subsample': 0.8500000000000001, 'classifier__colsample_bytree': 0.8500000000000001, 'classifier__max_depth': 11.0}\n"
     ]
    }
   ],
   "source": [
    "n_iteration = 0\n",
    "def objective(params,X,y,estimator,scorer,cv):\n",
    "    global n_iteration\n",
    "    # this is unfortunately a necessity because we have to transform floats to int\n",
    "    params['classifier__n_estimators'] = int(params['classifier__n_estimators'])\n",
    "    params['classifier__max_depth'] = int(params['classifier__max_depth'])\n",
    "    \n",
    "    estimator.set_params(**params)\n",
    "    #since r2 is normally maximized\n",
    "    score = 1.-cross_val_score(estimator, X, y, scoring=scorer, cv=cv).mean()\n",
    "    print(\"- iter {}: mean_score {:.5f}\".format(n_iteration,1.-score))\n",
    "    n_iteration += 1\n",
    "    return {'loss': score, 'status': STATUS_OK}\n",
    "\n",
    "cv_dev = RepeatedKFold(n_splits=3,n_repeats=5)\n",
    "\n",
    "trials_data = Trials() #define a database which will retain the trials\n",
    "xgb_space = {\n",
    "    'classifier__n_estimators': hp.quniform('classifier__n_estimators', 50, 500,1),#hp.choice('regressor__n_estimators', np.arange(50, 600, dtype=int)),\n",
    "     'classifier__learning_rate': hp.quniform('classifier__learning_rate', 0.025, 0.25, 0.025), # A problem with max_depth casted to float instead of int with the hp.quniform method.\n",
    "      'classifier__max_depth':  hp.quniform('classifier__max_depth', 1, 20,1),\n",
    "      'classifier__min_child_weight': hp.quniform('classifier__min_child_weight', 1, 10, 1),\n",
    "        'classifier__subsample': hp.quniform('classifier__subsample', 0.7, 1, 0.05),\n",
    "       'classifier__gamma': hp.quniform('classifier__gamma', 0., 1, 0.05),\n",
    "        'classifier__colsample_bytree': hp.quniform('classifier__colsample_bytree', 0.7, 1, 0.05),\n",
    "        'classifier__reg_alpha' :  hp.quniform('classifier__reg_alpha', 0, 10, 1),\n",
    "        'classifier__reg_lambda': hp.quniform('classifier__reg_lambda', 0, 10, 1)\n",
    "}\n",
    "space = hp.choice('0',\n",
    "    [{'features__columns':\n",
    "      hp.choice('features__columns',\n",
    "                [\n",
    "                    [['sepal_length','sepal_width'],['petal_length'],['petal_width']],\n",
    "                    [['sepal_length'],['sepal_width','petal_length'],['petal_width']] \n",
    "                    #Note that you can easily write code to generate all the partitions\n",
    "                ]),\n",
    "      **xgb_space}]\n",
    ")\n",
    "     \n",
    "\n",
    "best = fmin(fn=partial(objective,X=X,y=y,estimator=estimator,scorer=current_scorer(),cv=cv_dev),\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            trials = trials_data,\n",
    "            max_evals= 20)\n",
    "print('best result with accuracy score {}'.format(1.-trials_data.best_trial['result']['loss']))\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_time</th>\n",
       "      <th>exp_key</th>\n",
       "      <th>misc</th>\n",
       "      <th>owner</th>\n",
       "      <th>refresh_time</th>\n",
       "      <th>result</th>\n",
       "      <th>spec</th>\n",
       "      <th>state</th>\n",
       "      <th>tid</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-05-01 14:51:53.284</td>\n",
       "      <td>None</td>\n",
       "      <td>{'cmd': ('domain_attachment', 'FMinIter_Domain...</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-05-01 14:51:53.762</td>\n",
       "      <td>{'loss': 0.06222222222222229, 'status': 'ok'}</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-05-01 14:51:53.770</td>\n",
       "      <td>None</td>\n",
       "      <td>{'cmd': ('domain_attachment', 'FMinIter_Domain...</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-05-01 14:51:54.205</td>\n",
       "      <td>{'loss': 0.05111111111111122, 'status': 'ok'}</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-05-01 14:51:54.250</td>\n",
       "      <td>None</td>\n",
       "      <td>{'cmd': ('domain_attachment', 'FMinIter_Domain...</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-05-01 14:51:54.683</td>\n",
       "      <td>{'loss': 0.06000000000000005, 'status': 'ok'}</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-05-01 14:51:54.689</td>\n",
       "      <td>None</td>\n",
       "      <td>{'cmd': ('domain_attachment', 'FMinIter_Domain...</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-05-01 14:51:54.837</td>\n",
       "      <td>{'loss': 0.046666666666666856, 'status': 'ok'}</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-05-01 14:51:54.843</td>\n",
       "      <td>None</td>\n",
       "      <td>{'cmd': ('domain_attachment', 'FMinIter_Domain...</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-05-01 14:51:55.217</td>\n",
       "      <td>{'loss': 0.06222222222222229, 'status': 'ok'}</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                book_time exp_key  \\\n",
       "0 2018-05-01 14:51:53.284    None   \n",
       "1 2018-05-01 14:51:53.770    None   \n",
       "2 2018-05-01 14:51:54.250    None   \n",
       "3 2018-05-01 14:51:54.689    None   \n",
       "4 2018-05-01 14:51:54.843    None   \n",
       "\n",
       "                                                misc owner  \\\n",
       "0  {'cmd': ('domain_attachment', 'FMinIter_Domain...  None   \n",
       "1  {'cmd': ('domain_attachment', 'FMinIter_Domain...  None   \n",
       "2  {'cmd': ('domain_attachment', 'FMinIter_Domain...  None   \n",
       "3  {'cmd': ('domain_attachment', 'FMinIter_Domain...  None   \n",
       "4  {'cmd': ('domain_attachment', 'FMinIter_Domain...  None   \n",
       "\n",
       "             refresh_time                                          result  \\\n",
       "0 2018-05-01 14:51:53.762   {'loss': 0.06222222222222229, 'status': 'ok'}   \n",
       "1 2018-05-01 14:51:54.205   {'loss': 0.05111111111111122, 'status': 'ok'}   \n",
       "2 2018-05-01 14:51:54.683   {'loss': 0.06000000000000005, 'status': 'ok'}   \n",
       "3 2018-05-01 14:51:54.837  {'loss': 0.046666666666666856, 'status': 'ok'}   \n",
       "4 2018-05-01 14:51:55.217   {'loss': 0.06222222222222229, 'status': 'ok'}   \n",
       "\n",
       "   spec  state  tid  version  \n",
       "0  None      2    0        0  \n",
       "1  None      2    1        0  \n",
       "2  None      2    2        0  \n",
       "3  None      2    3        0  \n",
       "4  None      2    4        0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(trials_data.trials)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gpu]",
   "language": "python",
   "name": "conda-env-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
